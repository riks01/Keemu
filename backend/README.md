# KeeMU Backend - Content Intelligence Assistant

Production-ready backend for KeeMU, an AI-powered content aggregation and intelligence platform.

## ğŸš€ Features

- **Content Collection**: Automated monitoring of YouTube channels, Reddit communities, and blogs
- **Intelligent Processing**: RAG-powered chat interface for exploring content
- **Smart Summarization**: AI-generated summaries using Claude Haiku 3.5
- **Local Embeddings**: Cost-effective embeddings using google/embeddinggemma-300m
- **Scalable Architecture**: Async processing with Celery, Redis, and PostgreSQL
- **Production Ready**: Docker-based deployment with health checks and monitoring

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ FastAPI Application (REST API)
â”œâ”€â”€ PostgreSQL + pgvector (Data & Vector Storage)
â”œâ”€â”€ Redis (Cache & Message Broker)
â”œâ”€â”€ Celery Workers (Background Processing)
â”œâ”€â”€ Celery Beat (Scheduled Tasks)
â””â”€â”€ Flower (Task Monitoring)
```

## ğŸ“‹ Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)
- API Keys (see [API_SETUP_GUIDE.md](../API_SETUP_GUIDE.md))

## ğŸ› ï¸ Quick Start

### 1. Clone and Setup Environment

```bash
cd backend

# Copy environment template
cp env.template .env

# Edit .env with your API keys
nano .env
```

### 2. Start with Docker Compose

```bash
# Build and start all services
docker-compose up --build

# Or run in detached mode
docker-compose up -d --build
```

### 3. Verify Services

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Flower (Celery Monitor)**: http://localhost:5555
- **PostgreSQL**: localhost:5432
- **Redis**: localhost:6379

### 4. Check Health

```bash
curl http://localhost:8000/health
```

## ğŸ’» Local Development (without Docker)

### Install Dependencies

```bash
# Install Poetry (if not installed)
curl -sSL https://install.python-poetry.org | python3 -

# Install dependencies
poetry install

# Activate virtual environment
poetry shell
```

### Setup Database

```bash
# Start only database services
docker-compose up postgres redis -d

# Run migrations
alembic upgrade head
```

### Run Application

```bash
# Start API server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Start Celery worker (in another terminal)
celery -A app.workers.celery_app worker --loglevel=info

# Start Celery beat (in another terminal)
celery -A app.workers.celery_app beat --loglevel=info
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ auth.py      # Authentication routes
â”‚   â”‚       â”œâ”€â”€ sources.py   # Content source management
â”‚   â”‚       â”œâ”€â”€ summaries.py # Summary endpoints
â”‚   â”‚       â””â”€â”€ chat.py      # RAG chat interface
â”‚   â”œâ”€â”€ core/                # Core configuration
â”‚   â”‚   â”œâ”€â”€ config.py        # Settings management
â”‚   â”‚   â”œâ”€â”€ logging.py       # Structured logging
â”‚   â”‚   â””â”€â”€ security.py      # JWT & OAuth
â”‚   â”œâ”€â”€ models/              # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ content.py
â”‚   â”‚   â””â”€â”€ conversation.py
â”‚   â”œâ”€â”€ schemas/             # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ content.py
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ auth/            # Authentication service
â”‚   â”‚   â”œâ”€â”€ collectors/      # Content collectors
â”‚   â”‚   â”‚   â”œâ”€â”€ youtube.py
â”‚   â”‚   â”‚   â”œâ”€â”€ reddit.py
â”‚   â”‚   â”‚   â””â”€â”€ blog.py
â”‚   â”‚   â”œâ”€â”€ processors/      # Content processing
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”‚   â””â”€â”€ normalizer.py
â”‚   â”‚   â”œâ”€â”€ rag/             # RAG system
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”‚   â”œâ”€â”€ reranker.py
â”‚   â”‚   â”‚   â””â”€â”€ generator.py
â”‚   â”‚   â””â”€â”€ summaries/       # Summary generation
â”‚   â”œâ”€â”€ workers/             # Celery tasks
â”‚   â”‚   â”œâ”€â”€ celery_app.py
â”‚   â”‚   â”œâ”€â”€ collection.py
â”‚   â”‚   â”œâ”€â”€ processing.py
â”‚   â”‚   â””â”€â”€ summarization.py
â”‚   â”œâ”€â”€ db/                  # Database utilities
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â””â”€â”€ base.py
â”‚   â”œâ”€â”€ utils/               # Helper functions
â”‚   â””â”€â”€ main.py              # FastAPI application
â”œâ”€â”€ alembic/                 # Database migrations
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ docker/                  # Docker configs
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml           # Dependencies
â””â”€â”€ README.md
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_auth.py

# Run with verbose output
pytest -v
```

## ğŸ“Š Monitoring

### Celery Tasks

Access Flower dashboard: http://localhost:5555

### Logs

```bash
# View API logs
docker-compose logs -f api

# View Celery worker logs
docker-compose logs -f celery_worker

# View all logs
docker-compose logs -f
```

### Database

```bash
# Connect to PostgreSQL
docker-compose exec postgres psql -U keemu_user -d keemu_db

# Check vector extension
docker-compose exec postgres psql -U keemu_user -d keemu_db -c "SELECT * FROM pg_extension WHERE extname = 'vector';"
```

## ğŸ”§ Configuration

All configuration is managed through environment variables (see `env.template`).

### Key Configuration Areas

- **Cost/Performance**: Toggle between local/cloud models
- **Vector Database**: Switch between pgvector and Pinecone
- **Processing**: Adjust batch sizes and chunk sizes
- **Rate Limiting**: Configure API rate limits
- **Features**: Enable/disable email notifications, analytics, etc.

## ğŸ“ˆ Performance Optimization

### Local Embeddings

Using `google/embeddinggemma-300m` saves ~$0.13 per million tokens compared to OpenAI embeddings.

### Batch Processing

Configured batch sizes for optimal throughput:
- Embeddings: 32 items/batch
- Content collection: 50 items/batch

### Caching

Redis caching for:
- Frequently accessed summaries
- User sessions
- Rate limiting

## ğŸ› Troubleshooting

### Port Already in Use

```bash
# Check what's using the port
lsof -i :8000

# Stop conflicting service or change port in docker-compose.yml
```

### Database Connection Issues

```bash
# Ensure PostgreSQL is ready
docker-compose ps postgres

# Check logs
docker-compose logs postgres
```

### Celery Tasks Not Running

```bash
# Check Redis connection
docker-compose exec redis redis-cli ping

# Restart Celery worker
docker-compose restart celery_worker
```

### Model Download Issues

First run will download the embedding model (~300MB). Ensure stable internet connection.

```bash
# Check model cache
docker-compose exec api ls -la /root/.cache/huggingface
```

## ğŸš¢ Deployment

### Production Checklist

- [ ] Change `SECRET_KEY` and `JWT_SECRET_KEY` to strong random values
- [ ] Set `APP_ENV=production` and `DEBUG=false`
- [ ] Configure proper `ALLOWED_ORIGINS`
- [ ] Enable HTTPS/TLS
- [ ] Set up proper logging aggregation
- [ ] Configure Sentry for error tracking
- [ ] Set up database backups
- [ ] Configure resource limits in docker-compose
- [ ] Enable rate limiting
- [ ] Set up monitoring and alerts

### Environment-Specific Settings

Create separate `.env` files:
- `.env.development`
- `.env.staging`
- `.env.production`

## ğŸ“š API Documentation

When running in development mode, interactive API documentation is available:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ¤ Contributing

See main project README for contribution guidelines.

## ğŸ“ License

See LICENSE file in project root.

## ğŸ“ Support

For issues and questions, please open a GitHub issue.

---

**Status**: Stage One Development - Backend Infrastructure âœ…

**Next**: Stage Two - Frontend Development
